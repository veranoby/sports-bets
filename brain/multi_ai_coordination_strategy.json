{
  "üìã_TABLE_OF_CONTENTS": {
    "ai_roles_and_preferences": "Lines 5-35 (READ FIRST - Core Configuration)",
    "critical_rules": "Lines 36-515 (Non-negotiable Protocols - INCLUDES DIRECTOR_PLANNING_PROTOCOL + AUDIT_METHODOLOGY_PROTOCOL + UI_VERIFICATION_PROTOCOL + SOURCE_VERIFICATION_BEFORE_USAGE_PROTOCOL + PROTOCOL_EXECUTION_DISCIPLINE + IMPLEMENTATION_AND_REPORTING_OPTIMIZATION)",
    "role_responsibilities": "Lines 398-466",
    "execution_workflows": "Lines 467-556",
    "validation_gates": "Lines 557-616",
    "failure_recovery": "Lines 617-706",
    "recommended_practices": "Lines 707-896",
    "business_clarifications": "Lines 897-996",
    "implementation_and_reporting_framework": "Lines 953-1225 (Git-based evidence, backlog integrity, audit framework)"
  },

  "metadata": {
    "version": "5.5",
    "updated": "2025-12-02",
    "purpose": "Role-based AI orchestration framework - decoupled, resilient, and future-proof.",
    "note": "This file is READ-FIRST by all AIs. Core logic is based on ROLES, not specific models. Model selection is a configuration preference.",
    "prompt_files_location": "PROJECT ROOT (director-prompt.json, executor-prompt.json) - Role-based prompts for easier AI access.",
    "changelog_v5.5": "Added SOURCE_VERIFICATION_BEFORE_USAGE_PROTOCOL (lines 401-515) - MANDATORY: Read source definition before destructuring/using external functions/hooks/types. Prevents assumption-based errors (loading vs isLoading). Incident lesson: 2025-12-02 Gemini's 95% correct implementation broken by 1-word property name typo. Universal protocol for all external reference usage.",
    "changelog_v5.4": "Added IMPLEMENTATION_AND_REPORTING_OPTIMIZATION_FRAMEWORK (lines 953-1225) - MANDATORY git commit evidence for all work reports. Prevents temporal mismatches and false feature claims. Based on 2025-11-27 Opci√≥n B Audit: 47 claims verified, 95.7% accuracy. Establishes git_commits field requirement, temporal validation protocol, backlog integrity standards, and bidirectional audit framework. Zero tolerance: No backlog updates without git evidence after 2025-11-27.",
    "changelog_v5.3": "Added UI_VERIFICATION_PROTOCOL (lines 283-396) - Prevents false affirmations about UI implementation. MANDATORY: Read .tsx/.jsx component files before claiming UI displays data. Never infer rendering from backend/hooks/interfaces alone. Incident lesson: 2025-11-27 SystemHealthBadge metrics claim without reading component JSX.",
    "changelog_v5.2": "Added AUDIT_AND_ANALYSIS_METHODOLOGY_PROTOCOL (lines 147-281) - Prevents unidirectional search, tool validation failures, and 'absence of finding = absence of existence' errors. Incident lesson: 2025-11-11 backend audit missed existing endpoints.",
    "changelog_v5.1": "Added DIRECTOR_PLANNING_PROTOCOL (lines 79-101) - Director MUST read this file BEFORE creating executor plans to incorporate all critical error prevention protocols"
  },

  "ai_roles_and_preferences": {
    "description": "Defines the abstract roles in the system and the preferred models for each role. This allows for dynamic model swapping without changing core logic.",
    "director": {
      "description": "Responsible for architecture, planning, validation, high-level oversight, and declaring execution mode.",
      "preferred_models": [
        "claude-sonnet-4-5",
        "claude-opus-4",
        "glm-4-6"
      ],
      "forbidden_models": [
        "haiku-4-5"
      ]
    },
    "executor": {
      "description": "Responsible for specific, bounded implementation tasks (backend API, frontend components). Operates under a plan from the director.",
      "preferred_models": [
        "qwen3-coder-plus-2025-09-23",
        "gemini-2.0-flash-thinking-exp"
      ],
      "forbidden_models": []
    }
  },

  "execution_mode": {
    "description": "Global setting that dictates the level of validation and friction in the workflow. MUST be declared at session start by the AI in the 'director' role.",
    "standard": {
      "description": "Default mode. Maximum safety and validation. All protocols, simulations, and gates are strictly enforced. Recommended for complex tasks, database work, or high-risk changes.",
      "implications": [
        "simulate_y_confirmar_protocol is MANDATORY for all code changes.",
        "All validation_gates (TypeScript, build, etc.) are MANDATORY.",
        "Strict adherence to scope and file lists."
      ]
    },
    "trusted": {
      "description": "Expert mode for low-risk, high-speed iterations. Allows skipping certain non-critical validation steps for simple, well-understood tasks. Requires explicit user confirmation to activate.",
      "implications": [
        "simulate_y_confirmar_protocol can be SKIPPED for tasks with complexity='LOW'.",
        "npm run build gate can be SKIPPED for UI-only changes (e.g., CSS, text) after TypeScript validation.",
        "AI is allowed more autonomy, but must still report scope violations.",
        "User activation required: 'Activating TRUSTED mode for this session. Confirm Y/N?'"
      ]
    }
  },

  "üî¥_MCP_ACTIVATION_FOR_ALL_AIS": {
    "severity": "CRITICAL",
    "when_to_activate": {
      "database_sql_work": {"mcps": ["--c7", "--context7"], "why": "PostgreSQL type system expertise"},
      "multi_step_backend": {"mcps": ["--seq", "--sequential"], "why": "Dependency planning"},
      "react_typescript": {"mcps": ["--c7", "--context7"], "why": "React + TypeScript patterns"},
      "responsive_design": {"mcps": ["--play", "--playwright"], "why": "UI validation"},
      "code_analysis": {"mcps": ["--seq", "--sequential"], "why": "Systematic decomposition"}
    },
    "incident_lesson": "2025-10-30: PostgreSQL error occurred without Context7. LESSON: MCPs aren't optional - they're mandatory for quality."
  },

  "üî¥_DIRECTOR_PLANNING_PROTOCOL": {
    "severity": "CRITICAL",
    "principle": "Director AI MUST read this coordination strategy file BEFORE creating ANY plan for executor work",
    "rule": "When tasked with creating executor plans (JSON prompts, task specifications, work plans): Read brain/multi_ai_coordination_strategy.json FIRST, THEN create plan incorporating all critical protocols",
    "rationale": "Plans created without reading this file miss critical error prevention protocols, waste tokens on corrections, and risk executor failures",
    "mandatory_sequence_for_plan_creation": [
      "Step 1: User requests plan creation for executor work",
      "Step 2: IMMEDIATELY read brain/multi_ai_coordination_strategy.json (DO NOT skip this)",
      "Step 3: Identify which critical protocols apply (task_disambiguation, reporting_location, session_context_loss, evidence_based_validation)",
      "Step 4: Create plan incorporating ALL applicable protocols with explicit references to strategy file",
      "Step 5: Verify plan includes: session start declaration, task echo back, exact reporting location, checkpoint protocol, evidence requirements",
      "Step 6: Present plan to user"
    ],
    "critical_elements_every_executor_plan_must_include": {
      "session_start_protocol": "Mandatory declaration: Model + Role + Mode + Task echo back with user confirmation",
      "reporting_location": "EXACT file path where executor must report (not vague 'update brain/' instructions)",
      "session_management": "Hard time limits + checkpoint frequency + context refresh triggers + handoff note format",
      "evidence_requirements": "Specific command outputs and metrics executor must provide as proof of completion",
      "reference_to_protocols": "Explicit line number citations from this coordination strategy file"
    },
    "enforcement": "If director creates plan without reading this file first: User should reject plan and instruct director to read coordination strategy, then recreate plan",
    "lesson_learned": "Creating plans from memory or assumptions leads to missing critical protocols that prevent executor errors. Always read source of truth first."
  },

  "üî¥_ROLE_AND_MODEL_AWARENESS_PROTOCOL": {
    "severity": "CRITICAL",
    "rule": "Every AI session MUST start by declaring its model, its assigned ROLE, and task appropriateness.",
    "role_model_validation": "The directing AI (or the user) MUST validate that the declared model is in the 'preferred_models' list for its assigned role and NOT in the 'forbidden_models' list.",
    "inappropriate_model_for_role": "If a model is assigned to a role for which it is forbidden (e.g., Haiku as director), the session must be STOPPED. The AI must refuse and recommend a valid model from the preferred list for that role.",
    "unknown_task_protocol": {
      "description": "Protocol for when an AI cannot classify a task into a known pattern.",
      "trigger": "AI classifies task as 'not in MCP table' or 'not covered by existing workflows'.",
      "action": "STOP and report: 'Task [description] does not match known patterns. Requires human definition of a new protocol or manual execution. Awaiting instructions.'",
      "enforcement": "AI MUST NOT attempt to execute an unknown task with a guessed protocol."
    },
    "director_start_protocol": [
      "Read ~/.claude/CLAUDE.md",
      "Read project CLAUDE.md",
      "Read brain/multi_ai_coordination_strategy.json",
      "Declare execution_mode",
      "Classify task",
      "Check MCP table",
      "Activate agents/MCPs",
      "Document activation",
      "Proceed"
    ],
    "enforcement": "If an AI is assigned a role it cannot fulfill, or fails to declare its role and model, the user must interrupt and restart the session."
  },

  "üî¥_BASIC_PROTOCOL_ALL_AIS": {
    "severity": "CRITICAL",
    "rule_1": "READ COMPLETELY - Don't assume context. If user says 'I deleted users except admin' ‚Üí that's a FACT.",
    "rule_2": "NO FILE CREATION - Reports go in chat text only. Updates go to brain/ only. NEVER create .md files.",
    "rule_3": "BRAIN = SOURCE OF TRUTH - Update brain/ after every major task. Never scatter docs across root.",
    "rule_4": "EFFICIENCY NOT SPEED - Plan before executing. Trust user's explicit statements. Don't re-verify what they already confirmed.",
    "rule_5": "REPORT IN TEXT - Analysis happens in chat message area, not separate files."
  },

  "debugging_methodology_protocol": {
    "when": "User reports error with stack trace, or previous fix attempts failed",
    "responsible_ai": "AI in the 'director' role (root-cause-analyst mode recommended)",
    "step_1_analyze_not_fix": "PAUSE - Do NOT modify code yet. Ask: 'What assumptions could cause this? What conditions must be true?'",
    "step_2_identify_root_causes": "Walk through AT LEAST 2 possible causes based on stack trace and common misuse patterns",
    "step_3_validate_hypothesis": "Propose fix with specific test steps to validate (e.g., 'Add console.log(context) before failing line')",
    "step_4_avoid_repeats": "Never repeat previous failed attempts. Ask clarifying questions if uncertain.",
    "enforcement": "Director AI checks root cause BEFORE proposing fix"
  },

  "üî¥_AUDIT_AND_ANALYSIS_METHODOLOGY_PROTOCOL": {
    "severity": "CRITICAL",
    "principle": "Comprehensive, bidirectional verification with tool validation. Absence of finding ‚â† absence of existence.",
    "applicability": "All audit tasks, analysis requests, discrepancy investigations, or 'confirm X is reflected in Y' type requests",

    "core_rules": {
      "rule_1_bidirectional_search": {
        "description": "For any 'A vs B' comparison, search BOTH directions",
        "examples": [
          "Backend audit: Check (1) brain ‚Üí backend: 'Is documented endpoint implemented?' AND (2) backend ‚Üí brain: 'Is implemented endpoint documented?'",
          "File analysis: Check (1) 'Does file X contain Y?' AND (2) 'What else is in file X that we haven't accounted for?'"
        ],
        "enforcement": "MANDATORY for all audit/analysis tasks. Both directions must be explicitly performed and reported."
      },

      "rule_2_tool_validation": {
        "description": "Verify tool outputs are valid before trusting results",
        "trigger_scenarios": [
          "Grep/search returns empty ‚Üí VERIFY with direct file Read",
          "Command shows '0 results' ‚Üí CONFIRM with alternative method",
          "Unexpected result from automation ‚Üí MANUALLY VERIFY sample"
        ],
        "protocol_when_tool_fails": [
          "Step 1: Acknowledge tool may have failed (syntax error, path issue, etc.)",
          "Step 2: Switch to direct method (Read file, manual inspection)",
          "Step 3: Document which tool failed and why in report",
          "Step 4: Use validated method for remaining work"
        ],
        "enforcement": "NEVER assume 'empty result = nothing exists' without validation"
      },

      "rule_3_systematic_coverage": {
        "description": "Enumerate search space completely before concluding",
        "checklist": [
          "List all files/endpoints/entities in scope",
          "Create explicit checklist of what to verify",
          "Check off items as verified (not assumed)",
          "Report both 'verified present' AND 'verified absent' findings"
        ],
        "anti_pattern": "Checking a few examples and extrapolating",
        "enforcement": "For audits: Provide counts (X files checked, Y endpoints verified, Z discrepancies found)"
      },

      "rule_4_direct_inspection": {
        "description": "When in doubt, read the source directly",
        "trigger": "Any of: (1) Tool returns unexpected result, (2) Critical finding needs confirmation, (3) Ambiguity in automated results",
        "method": "Use Read tool with specific offset/limit to manually inspect actual code/config/data",
        "enforcement": "Grep is for discovery, Read is for validation"
      },

      "rule_5_explicit_assumptions": {
        "description": "State and validate all assumptions before concluding",
        "process": [
          "List assumptions being made (e.g., 'Assuming all routes are in routes/ directory')",
          "Validate each assumption explicitly (e.g., 'Verified: grep shows no routes defined elsewhere')",
          "Document validated assumptions in report"
        ],
        "enforcement": "Report must include 'Assumptions Made' and 'Assumptions Validated' sections for complex audits"
      }
    },

    "audit_workflow_template": {
      "phase_1_scope_definition": [
        "Define exactly what to audit (files, endpoints, configs, etc.)",
        "List all sources of truth to compare against",
        "Create explicit checklist of verification items"
      ],
      "phase_2_bidirectional_search": [
        "Direction A‚ÜíB: Check source A against target B",
        "Direction B‚ÜíA: Check target B against source A",
        "Document both forward and reverse findings separately"
      ],
      "phase_3_tool_validation": [
        "If any search returns unexpected/empty: STOP",
        "Validate tool output with direct Read/inspection",
        "Switch to validated method if tool failed"
      ],
      "phase_4_gap_analysis": [
        "Documented but not implemented ‚Üí Missing implementations",
        "Implemented but not documented ‚Üí Missing docs",
        "Mismatches ‚Üí Discrepancies to resolve"
      ],
      "phase_5_reporting": [
        "Provide counts and metrics (X checked, Y found, Z missing)",
        "List specific findings with file:line references",
        "Include validation method used for each finding",
        "State assumptions and limitations explicitly"
      ]
    },

    "incident_lesson_2025_11_11": {
      "task": "User requested backend audit to verify brain/ documentation accuracy",
      "what_went_wrong": [
        "Only searched documented ‚Üí backend (found missing GET /bets/all)",
        "Did NOT search backend ‚Üí documented (missed 3 wallet financial endpoints)",
        "Grep failed with syntax error, did not validate with Read",
        "Assumed 'empty grep result = endpoint does not exist'"
      ],
      "impact": [
        "Reported 'Finance endpoints need implementation' when they already existed",
        "Wasted user's time asking for decision on implementation",
        "Only discovered endpoints existed when implementing 'new' endpoints"
      ],
      "root_cause": "Unidirectional search + tool failure without validation + assumption without verification",
      "correct_approach": [
        "Step 1: List all backend routes (ls backend/src/routes/*.ts)",
        "Step 2: For each route file, grep all router.get/post/put/delete",
        "Step 3: Compare against brain/api_endpoints_reference.json paths",
        "Step 4: Direction A: brain ‚Üí backend (missing implementations)",
        "Step 5: Direction B: backend ‚Üí brain (missing documentation)",
        "Step 6: If grep fails, Read file directly with offset/limit",
        "Step 7: Report both directions with counts"
      ]
    },

    "enforcement_checklist": {
      "before_concluding_audit": [
        "‚úÖ Both directions searched (A‚ÜíB AND B‚ÜíA)",
        "‚úÖ Tool outputs validated (especially empty/unexpected results)",
        "‚úÖ Complete enumeration performed (not sampling)",
        "‚úÖ Direct inspection used for critical findings",
        "‚úÖ Assumptions explicitly stated and validated",
        "‚úÖ Report includes metrics (X total, Y verified, Z discrepancies)"
      ],
      "red_flags_to_stop_and_validate": [
        "üö® Grep returns 0 results when you expected matches",
        "üö® Tool command exits without output or with error",
        "üö® Finding seems inconsistent with known system architecture",
        "üö® Only checked one direction of A vs B comparison",
        "üö® Relying on assumptions not explicitly verified"
      ]
    },

    "applicability": "All AIs performing audits, analysis, verification, or 'confirm X matches Y' tasks"
  },

  "üî¥_UI_VERIFICATION_PROTOCOL": {
    "severity": "CRITICAL",
    "principle": "Never affirm about UI implementation without reading actual component files. Interface contracts do not guarantee rendering implementation.",
    "applicability": "All questions about UI/frontend state: 'Is X displayed?', 'Does component show Y?', 'Is Z implemented in the interface?'",

    "core_violation": {
      "error_pattern": "Assuming UI displays data because backend sends it or hook returns it",
      "example": "Backend returns metrics ‚Üí Hook has metrics field ‚Üí [FALSE ASSUMPTION] ‚Üí Component displays metrics",
      "correct_pattern": "Backend returns metrics ‚Üí Hook has metrics field ‚Üí [READ COMPONENT] ‚Üí Verify JSX rendering"
    },

    "mandatory_verification_workflow": {
      "step_1_stop_before_affirming": {
        "trigger": "User asks: 'Is [UI_ELEMENT] displayed/implemented/shown?'",
        "action": "STOP - Do NOT answer based on backend/hooks/interfaces",
        "rationale": "Data availability ‚â† UI implementation"
      },
      "step_2_read_component_file": {
        "action": "Read the .tsx/.jsx component file that would render the UI element",
        "required": "MANDATORY - No exceptions",
        "target_lines": "Focus on JSX return statement and render logic (typically last 30-50% of file)"
      },
      "step_3_search_jsx_rendering": {
        "action": "Search for specific JSX elements that would render the feature",
        "examples": [
          "Looking for metrics display? Search for '{metrics.memory' or 'metrics?.database' in JSX",
          "Looking for button? Search for '<button' or 'onClick=' with relevant handler name",
          "Looking for modal? Search for modal component name and its props"
        ],
        "validation": "Must find actual JSX tags/elements, not just TypeScript logic"
      },
      "step_4_cite_evidence": {
        "requirement": "Quote specific line numbers from component file",
        "format": "[ComponentName.tsx:150-165] shows <div>{metrics.memory.currentMB}</div>",
        "anti_pattern": "Saying 'Yes it's implemented' without line number citation"
      },
      "step_5_respond_with_evidence": {
        "if_found": "Confirm with line citations: 'Yes, [feature] is rendered at [file:lines]'",
        "if_not_found": "Deny with evidence: 'No, reading [file] lines [X-Y] shows only [what_actually_exists]'",
        "never": "Never respond based on inference or assumptions"
      }
    },

    "common_false_assumption_patterns": {
      "backend_sends_equals_frontend_displays": {
        "false_logic": "API endpoint returns data ‚Üí UI must be showing it",
        "reality": "API can return 100 fields, UI may only display 3",
        "prevention": "Always read component to verify which fields are actually rendered"
      },
      "interface_has_field_equals_component_uses_it": {
        "false_logic": "TypeScript interface defines 'metrics' ‚Üí Component must display metrics",
        "reality": "Interface defines contract, component may destructure and ignore fields",
        "prevention": "Search for actual usage in JSX, not just in destructuring/props"
      },
      "hook_returns_data_equals_ui_shows_data": {
        "false_logic": "useData() hook returns X ‚Üí Component calling useData() shows X",
        "reality": "Component may call hook but only use subset of returned data",
        "prevention": "Verify JSX rendering, not just hook invocation"
      }
    },

    "incident_lesson_2025_11_27": {
      "task": "User asked: 'Is AdminHeader showing detailed metrics (Memory MB, DB connections, Intervals)?'",
      "what_went_wrong": [
        "AI read useMonitoringAlerts.ts (hook) and saw it returned alertCount/criticalAlerts",
        "AI read monitoring.ts (backend) and saw it sent alert data",
        "AI ASSUMED SystemHealthBadge.tsx was displaying detailed metrics",
        "AI did NOT read SystemHealthBadge.tsx to verify actual JSX rendering"
      ],
      "actual_state": [
        "SystemHealthBadge.tsx:150-165 only showed '3 Critical Alerts' (generic count)",
        "NO detailed metrics were rendered (no Memory MB, no DB connections, no Intervals)"
      ],
      "impact": [
        "User caught the error and questioned the claim",
        "Wasted ~3,700 tokens on incorrect affirmation + correction cycle",
        "Loss of trust - user had to verify AI claims instead of trusting response"
      ],
      "correct_approach": [
        "Step 1: User asks about UI display",
        "Step 2: Read SystemHealthBadge.tsx (the actual component)",
        "Step 3: Search JSX for 'metrics.memory', 'metrics.database', 'metrics.intervals'",
        "Step 4: Find only generic '{alertCount} Critical Alerts' display",
        "Step 5: Respond: 'No, lines 150-165 show only alert counts, not detailed metrics'"
      ]
    },

    "enforcement_rules": {
      "rule_1_read_before_claim": "NEVER claim UI displays X without reading component .tsx/.jsx file",
      "rule_2_jsx_is_evidence": "Only JSX rendering counts as evidence, not TypeScript logic or interfaces",
      "rule_3_cite_line_numbers": "Always cite specific line numbers when confirming UI implementation",
      "rule_4_admit_when_uncertain": "If you haven't read the component yet, say so explicitly",
      "rule_5_inference_prohibition": "Prohibited: Inferring UI state from backend/hooks/contracts alone"
    },

    "token_waste_prevention": {
      "cost_of_false_affirmation": "~3,700 tokens for correction cycle (~$0.01 USD but high trust cost)",
      "prevention_cost": "~500 tokens to Read component file before answering",
      "efficiency_gain": "87% token savings + 100% accuracy by reading before affirming",
      "trust_preservation": "User confidence maintained when answers are evidence-based from first response"
    },

    "quick_reference_checklist": {
      "before_saying_yes_to_ui_question": [
        "‚òê Have I read the actual .tsx/.jsx component file?",
        "‚òê Have I searched the JSX return statement for the specific UI element?",
        "‚òê Can I cite line numbers where the element is rendered?",
        "‚òê Am I basing this on actual JSX, not on interfaces/hooks/backend?",
        "‚òê If NO to any above ‚Üí READ COMPONENT FIRST, then answer"
      ]
    },

    "applicability": "All AIs (director and executor) when answering questions about UI/frontend implementation, display, or rendering"
  },

  "üî¥_SOURCE_VERIFICATION_BEFORE_USAGE_PROTOCOL": {
    "severity": "CRITICAL",
    "principle": "Never assume property names, function signatures, or type structures. Always read the source definition before using.",
    "applicability": "All scenarios where AI destructures properties, calls functions, uses hooks, or references types",

    "incident_2025_12_02_gemini": {
      "what_happened": "Gemini implemented ProtectedRoute with 'const { loading: flagsLoading } = useFeatureFlags()' but hook returns 'isLoading' not 'loading'",
      "impact": "flagsLoading was undefined, loading guard never waited, race condition NOT fixed despite correct architecture",
      "root_cause": "Assumed conventional name 'loading' without reading hook definition",
      "lesson": "95% correct implementation broken by 1 word typo due to assumption"
    },

    "core_violation": {
      "error_pattern": "Using/destructuring from source without reading source definition first",
      "examples": [
        "const { prop1, prop2 } = useHook() // Without reading hook file",
        "myFunction(arg1, arg2) // Without verifying function signature",
        "interface.property // Without checking if property exists",
        "import { Thing } from './file' // Without verifying Thing is exported"
      ]
    },

    "mandatory_workflow": {
      "step_1_identify_external_reference": {
        "trigger": "About to use hook/function/type/component from another file",
        "action": "STOP - Do not write usage code yet"
      },
      "step_2_read_source_definition": {
        "action": "Read the file that defines the hook/function/type",
        "command": "Read [source_file] or grep -A 20 'export const hookName'",
        "focus": "Return type, exported properties, function signature, type definition"
      },
      "step_3_verify_exact_names": {
        "action": "Note exact property/parameter names from source",
        "examples": [
          "Hook returns { isLoading, isError } not { loading, error }",
          "Function expects (userId, options) not (id, settings)",
          "Type has 'userName' not 'username'"
        ]
      },
      "step_4_write_usage_with_verified_names": {
        "action": "Write code using EXACT names from source",
        "validation": "If unsure, re-read source. Never guess."
      },
      "step_5_run_type_checking": {
        "action": "npx tsc --noEmit immediately after writing",
        "purpose": "Catch property name errors before they cause runtime bugs"
      }
    },

    "prevention_rules": {
      "rule_1_no_convention_assumptions": {
        "wrong": "Assuming 'loading' because most hooks use that name",
        "right": "Reading hook file to see it returns 'isLoading'",
        "enforcement": "Conventions are guidelines, source is truth"
      },
      "rule_2_read_before_destructure": {
        "wrong": "const { a, b, c } = source() without reading source",
        "right": "Read source definition ‚Üí Note exact property names ‚Üí Then destructure",
        "enforcement": "MANDATORY for all destructuring from external sources"
      },
      "rule_3_verify_function_signatures": {
        "wrong": "Calling myFunc(arg1, arg2) based on intuition",
        "right": "Read function definition to verify parameter order and types",
        "enforcement": "Especially critical for functions with multiple parameters"
      },
      "rule_4_check_exports_before_import": {
        "wrong": "import { Thing } from './file' assuming Thing exists",
        "right": "grep 'export.*Thing' file.ts to verify export exists",
        "enforcement": "Prevents 'module has no exported member' errors"
      }
    },

    "quick_verification_commands": {
      "verify_hook_return_type": "grep -A 30 'export const useHook' hookFile.ts",
      "verify_function_signature": "grep -A 5 'export.*function.*myFunc' file.ts",
      "verify_type_definition": "grep -A 20 'export.*interface.*MyType' types.ts",
      "verify_export_exists": "grep 'export.*TargetName' file.ts"
    },

    "common_assumption_traps": {
      "loading_vs_isLoading": "Both common, don't assume",
      "error_vs_isError": "Both used, verify which",
      "data_vs_result": "Check actual return property name",
      "id_vs_userId": "Naming varies, read source",
      "onClick_vs_handleClick": "Prop names differ by component"
    },

    "enforcement_checklist": {
      "before_using_external_source": [
        "‚ñ° Have I read the file that defines this hook/function/type?",
        "‚ñ° Do I know the EXACT property/parameter names?",
        "‚ñ° Am I using the names from source, not assumptions?",
        "‚ñ° Will I run npx tsc after writing this code?",
        "‚ñ° If NO to any: Read source file NOW, then proceed"
      ]
    },

    "cost_benefit_analysis": {
      "cost_of_assumption": "~3 hours debugging + user frustration + loss of trust",
      "cost_of_verification": "~30 seconds to Read source file",
      "benefit": "100% prevention of property name errors",
      "roi": "360x time savings (30 sec vs 3 hours)"
    },

    "integration_with_existing_protocols": {
      "complements_UI_VERIFICATION": "Read component before claiming UI displays data",
      "complements_AUDIT_METHODOLOGY": "Verify tool outputs, don't assume",
      "complements_EVIDENCE_BASED": "Source code is evidence, not assumptions",
      "complements_PROTOCOL_DISCIPLINE": "Executing means reading source, not guessing"
    },

    "applicability": "ALL AIs when using any external function/hook/type/component. Universal prevention for assumption-based errors.",
    "enforcement": "TypeScript will catch these errors, but only AFTER wasting time. Read source BEFORE writing usage code to prevent entirely."
  },

  "üî¥_LEARNING_FROM_IMPLEMENTATION_ERRORS_PROTOCOL": {
    "severity": "CRITICAL",
    "principle": "Learn from implementation errors to prevent recurring patterns. Systematic analysis of mistakes improves future performance.",
    "applicability": "All AIs after identifying implementation errors in their own work or work they're reviewing",

    "common_error_patterns_identified": {
      "incorrect_relative_paths": {
        "description": "Using wrong relative path syntax (../../../ instead of ../../)",
        "root_cause": "Assuming path depth without verifying directory structure",
        "prevention": [
          "Always verify directory structure with 'find' or 'ls' commands before implementing",
          "Calculate path from target file to source file, not from project root",
          "Test import paths in the actual directory context"
        ]
      },
      "component_name_mismatches": {
        "description": "Using incorrect component names (ConfirmModal instead of ConfirmDialog)",
        "root_cause": "Assuming component exists with expected name without verifying actual file content",
        "prevention": [
          "Read component file to verify exact export name",
          "Check actual file content before implementing import",
          "Always use exact names from source files, not assumed variations"
        ]
      },
      "nonexistent_properties_or_props": {
        "description": "Passing props that don't exist on components (isConfirming on ConfirmDialog)",
        "root_cause": "Assuming component interface without checking actual TypeScript definition",
        "prevention": [
          "Read component TypeScript interface/props definition",
          "Verify available props before implementing",
          "Check component source to understand exact API"
        ]
      },
      "typescript_configuration_ignorance": {
        "description": "Ignoring project-specific TypeScript configurations (verbatimModuleSyntax)",
        "root_cause": "Not analyzing tsconfig.json for project-specific rules before implementation",
        "prevention": [
          "Always read tsconfig.json and related configuration files",
          "Understand specific rules like verbatimModuleSyntax, strict mode, etc.",
          "Apply correct import syntax based on configuration"
        ]
      },
      "chained_error_misidentification": {
        "description": "Misidentifying primary error when secondary errors mask the root cause",
        "root_cause": "Focusing on the first error message instead of analyzing the full error chain",
        "prevention": [
          "Analyze complete error output to identify primary vs secondary errors",
          "Trace error dependencies to find root cause",
          "Understand that fixing primary error may resolve multiple secondary errors"
        ]
      }
    },

    "error_analysis_workflow": {
      "step_1_stop_and_assess": {
        "trigger": "When implementation error is identified",
        "action": "PAUSE - Do NOT immediately start fixing",
        "rationale": "Rapid fixing without analysis often perpetuates the same error patterns"
      },
      "step_2_root_cause_identification": {
        "action": "Identify the fundamental cause of the error",
        "method": "Ask: 'Why did this happen at the systemic level?'",
        "focus": "Not just 'what went wrong' but 'what process failure allowed this?'"
      },
      "step_3_pattern_recognition": {
        "action": "Check if this error matches known patterns",
        "method": "Compare against common error patterns in this protocol",
        "extension": "Add new pattern if this is a previously unknown error type"
      },
      "step_4_prevention_strategy_development": {
        "action": "Create specific prevention strategy for this error type",
        "requirements": [
          "Specific steps to avoid in future",
          "Tools or checks that could prevent this error",
          "Review processes that could catch this error early"
        ]
      },
      "step_5_update_coordination_strategy": {
        "action": "Add new error pattern and prevention strategy to this document",
        "rationale": "Learning becomes institutional knowledge for all AIs",
        "format": "Follow same structure as existing error patterns"
      },
      "step_6_validation": {
        "action": "Verify prevention strategy would have stopped the original error",
        "method": "Apply new strategy to original scenario and confirm it would prevent the error"
      }
    },

    "quality_improvement_metrics": {
      "error_recurrence_tracking": "Track if same error pattern repeats after adding prevention strategy",
      "prevention_protocol_adoption": "Verify AIs are using new error prevention strategies",
      "learning_efficiency": "Measure reduction in similar error types after protocol implementation",
      "knowledge_transfer": "Ensure new error patterns are shared across AI sessions"
    },

    "enforcement": {
      "when_to_apply": "After any implementation error is identified (own work or reviewing others)",
      "required_actions": [
        "Document the specific error",
        "Analyze the root cause",
        "Identify the prevention strategy",
        "Update this coordination strategy with new pattern",
        "Verify prevention strategy would have stopped the error"
      ],
      "accountability": "All AIs are responsible for learning from errors and improving systemic processes"
    }
  },

  "role_responsibilities": {
    "director": {
      "primary": "Validation engine + architecture oversight + execution_mode declaration + task delegation to executors.",
      "mandatory": [
        "Declare model and role at session start: 'Model: [model_name] | Assigned Role: director | Mode: standard'",
        "TypeScript compilation after each executor session",
        "App.tsx routing verification for new pages",
        "Import/export dependency resolution",
        "Integration testing and gap filling",
        "Brain system updates with lessons learned",
        "Acknowledge and adhere to the current 'execution_mode' (trusted/standard) defined in the strategy.",
        "Delegate tasks to executors with clear, bounded instructions and file lists."
      ]
    },
    "executor": {
      "primary": "Backend API modifications or React component implementations (20-30 min sessions only). Operates under a plan from the director.",
      "mandatory": [
        "Declare model and role at session start: 'Model: [model_name] | Assigned Role: executor'",
        "ACTIVATE required MCPs BEFORE starting work (e.g., --seq for backend, --c7 for frontend).",
        "SIMULATE + CONFIRM protocol for all changes (unless in trusted mode for low complexity).",
        "npm install BEFORE using new libraries",
        "npx tsc --noEmit AFTER all code changes",
        "git diff --name-only BEFORE commit to verify scope",
        "Acknowledge and adhere to the current 'execution_mode' (trusted/standard) defined in the strategy.",
        "Report completion back to the director or user as specified."
      ],
      "forbidden": [
        "Making architecture decisions without director approval",
        "Modifying core files (e.g., Auth.ts, models, migrations) without explicit director approval",
        "Modifying files outside the provided [FILES_TO_MODIFY] list",
        "Committing code without TypeScript validation"
      ]
    }
  },

  "execution_workflows": {
    "simulate_y_confirmar_protocol": {
      "when": "Executor AI is about to modify code (routes, models, components, etc.).",
      "applicability_condition": "Applies if: execution_mode is 'standard' OR task.complexity is 'HIGH'.",
      "step_1_simulate": "Describe exactly what you'll change: files, imports, dependencies, test commands",
      "step_2_confirm": "Verify against actual codebase: Does file exist? Are imports available? Will this break anything?",
      "step_3_document": "[SIMULATED] ‚Üí [CONFIRMED] ‚Üí [MODIFIED] in commit message",
      "failure": "If simulation reveals problem ‚Üí REPORT it, do NOT attempt fix. Message: '[SIMULATION FAILED] Cannot [task]: Reason: [why] / Recommendation: [solution]'",
      "trusted_mode_exception": "In 'trusted' mode for complexity='LOW', this protocol can be skipped, but changes must still be verified with git diff before commit."
    },
    "checkpoint_system": {
      "when": "After any executor session creates/modifies pages",
      "verify": [
        "App.tsx routes: All created pages have Route entries?",
        "AdminSidebar.tsx: All admin pages have sidebar entries?",
        "Build passes: npm run build succeeds (unless skipped in trusted mode)?",
        "Commit has [WIRED] or [VERIFIED] tag?"
      ],
      "incident": "2025-10-18: Pages created but routes disappeared in intermediate commits"
    },
    "role_based_pipeline": {
      "phase_1_director_planning": "Director AI analyzes task, creates a detailed plan, and delegates to an executor.",
      "phase_2_executor_implementation": "Executor AI (Qwen/Gemini/etc.) implements the bounded task based on the plan.",
      "phase_3_director_validation": "Director AI validates the implementation, runs tests, updates the brain, and closes the loop."
    }
  },

  "validation_gates": {
    "role_and_model_appropriateness": {
      "check": "Is the model appropriate for the assigned role?",
      "validation_method": "Check 'ai_roles_and_preferences' to ensure the model is in 'preferred_models' and not in 'forbidden_models' for its role.",
      "enforcement": "First action of EVERY session: Model and role declaration + appropriateness verification.",
      "failure": "Session cannot proceed - recommend model/role switch to user."
    },
    "flag_activation_verification": {
      "when": "Before ANY code modification or database work",
      "required_declarations": [
        "Database/SQL work ‚Üí Must show: 'Activating --c7 --context7'",
        "Multi-step backend ‚Üí Must show: 'Activating --seq --sequential'",
        "React/TypeScript ‚Üí Must show: 'Activating --c7 --context7'",
        "UI testing ‚Üí Must show: 'Activating --play --playwright'"
      ],
      "verification_method": "AI must OUTPUT activation statement BEFORE starting work",
      "enforcement": "If AI starts work without declaring flags ‚Üí INVALID SESSION",
      "user_detection": "If no flag declaration in first 3 messages ‚Üí interrupt and ask AI to restart properly"
    },
    "typescript_compilation": {
      "command": "npx tsc --noEmit",
      "required": "ZERO errors. This gate is NEVER skippable, regardless of execution_mode.",
      "failure": "Stop session immediately, rollback, escalate to director AI"
    },
    "build_process": {
      "command": "npm run build",
      "required": "Successful completion in dist/.",
      "trusted_mode_exception": "In 'trusted' mode for low-risk UI-only changes (e.g., CSS, text content), this gate can be skipped after TypeScript validation passes. User must be informed.",
      "failure": "Full session rollback required (if not skipped)"
    },
    "dependency_check": {
      "command": "git diff HEAD package.json && npm install",
      "required": "All deps installed before using them",
      "enforcement": "Critical for executor AI (broke backend on 2025-10-14)"
    },
    "scope_validation": {
      "command": "git diff --name-only",
      "required": "ONLY files in [FILES_TO_MODIFY] changed",
      "failure": "REVERT scope violations before commit"
    }
  },

  "failure_recovery": {
    "unplanned_changes_analysis": {
      "detect": "git diff shows files outside AI task scope",
      "classify_as": {
        "error": "Syntax errors, broken builds, TODOs ‚Üí REVERT immediately",
        "destructive": "Breaks APIs, changes types, schema mods ‚Üí REVERT + investigate",
        "improvement": "ESLint formatting, code quality, performance ‚Üí RETAIN with [APPROVED_IMPROVEMENT] tag"
      }
    },
    "build_stability": {
      "typescript_fails": "Stop AI, rollback, document error patterns",
      "build_fails": "Full session rollback: git reset --hard HEAD~1",
      "imports_broken": "Fix paths immediately before proceeding"
    },
    "git_stash_safety": {
      "rule": "NEVER stash user's changes without explicit permission",
      "action": "ASK FIRST: 'About to stash [files]. OK?'",
      "document": "If stashing, record in brain/ with recovery command"
    }
  },

  "recommended_practices_optimization": {
    "system_maintenance_and_health_checks": {
      "description": "Best practices for the human operator to ensure the strategy file remains healthy and effective.",
      "strategies": [
        "Create a simple validation script (e.g., in Node.js or Python) that runs before starting AI work.",
        "The script should: a) Validate the JSON syntax of this file. b) Check if files referenced in 'tested_in_files' or other paths actually exist.",
        "Schedule a monthly review of the 'lessons_learned' sections to see if they can be generalized or if new patterns have emerged."
      ]
    },
    "strategies_for_perfect_json_work_plans": {
      "comprehensive_planning": [
        "Include all required file reads before starting work",
        "Identify dependencies and potential conflicts",
        "Define success criteria clearly",
        "List validation steps before implementation",
        "Plan for error handling and edge cases"
      ],
      "structured_formatting": [
        "Use consistent JSON structure with clear metadata",
        "Include file paths, required changes, and expected outcomes",
        "Document test commands and validation gates",
        "Provide fallback plans if primary approaches fail",
        "Specify rollback procedures for safety"
      ],
      "error_prevention": [
        "Pre-verification of all assumptions with codebase analysis",
        "Type compatibility checks before implementation",
        "Scope validation to prevent unwanted side effects",
        "Dependency mapping to understand impact of changes",
        "Mandatory TypeScript compilation after changes"
      ],
      "quality_assurance": [
        "Zero 'any' types enforcement in TypeScript projects",
        "Consistent pattern application across similar components",
        "Integration testing with existing codebase",
        "Performance impact analysis for database changes",
        "Security validation for user-facing features"
      ]
    },
    "json_plan_template": {
      "metadata": {
        "task_name": "Brief, descriptive task name",
        "complexity": "LOW/MEDIUM/HIGH",
        "execution_mode": "standard/trusted (to be decided by director)",
        "assigned_role": "director/executor",
        "estimated_time": "Minutes",
        "git_branch": "Target branch for work"
      },
      "critical_protocols": {
        "session_start_declaration": "Model and role declaration with task type and flags",
        "mcp_activation_mandatory": "Required MCPs for the specific task type",
        "simulate_confirm_protocol": "Explicit simulation and confirmation steps",
        "no_file_creation": "Restrictions on what can be created vs modified",
        "infinite_loop_prevention": "Prevention mechanisms for common loops"
      },
      "reference_files_read_first": [
        "List of required files to read before implementation",
        "Documentation that provides context",
        "Current implementations for consistency"
      ],
      "step_by_step_implementation": {
        "step_number": {
          "action": "Specific action to take",
          "file": "Target file for the action",
          "purpose": "Why this step is needed",
          "simulate": "What will be done in simulation phase",
          "confirm_before_creating": "What to verify before proceeding",
          "validate_after_creation": "How to validate the change"
        }
      },
      "success_criteria": [
        "Zero TypeScript errors",
        "Build process succeeds (if applicable)",
        "No 'any' types introduced",
        "Files modified only as specified",
        "All features implemented correctly"
      ],
      "error_handling": {
        "typescript_errors": "Stop immediately if compilation fails",
        "build_errors": "Do not commit if build fails",
        "infinite_loop_detection": "Stop if same file edited multiple times"
      }
    },
    "general_lessons_learned": {
      "pre_implementation_validation": {
        "description": "Always validate assumptions and read relevant files BEFORE implementation",
        "strategies": [
          "Read type/interface definitions before implementing functions",
          "Verify API signatures exist before calling them",
          "Check import paths and dependencies before starting work",
          "Understand the full scope of changes to prevent incomplete implementations"
        ]
      },
      "incremental_development": {
        "description": "Break complex tasks into smaller, verifiable steps",
        "strategies": [
          "Implement and test one feature at a time",
          "Use checkpoints to validate progress",
          "Verify each step before moving to the next",
          "Roll back immediately if any step fails validation"
        ]
      },
      "consistency_enforcement": {
        "description": "Maintain consistent patterns across the codebase",
        "strategies": [
          "Follow established naming conventions",
          "Use consistent component structures and props",
          "Apply uniform error handling patterns",
          "Maintain consistent data flow and state management"
        ]
      },
      "error_prevention_patterns": {
        "description": "Proactive strategies to prevent common implementation errors",
        "strategies": [
          "Type safety: Avoid 'any' types, use explicit interfaces",
          "Null safety: Use optional chaining and null checks",
          "API validation: Verify endpoints exist before implementation",
          "Dependency checking: Ensure all imports are available before use"
        ]
      }
    }
  },

  "business_model_clarifications_2025_10_30": {
    "events_venues": {
      "definition": "Events are competitions held AT venues (stadiums). events.venue_id ‚Üí user with role='venue'",
      "rule": "ONLY role='venue' users can host events. Not galleras, not regular users.",
      "semantic": "venue_id means 'physical location', not 'arbitrary owner'"
    },
    "articles_authors": {
      "definition": "Articles created BY users (admin/venue/gallera). articles.author_id ‚Üí creator",
      "rule": "Regular users CANNOT create articles. Only admin/venue/gallera roles.",
      "deprecated": "articles.venue_id should be removed after data consolidation"
    },
    "principle": "Foreign keys represent SEMANTIC relationships, not just type compatibility. Verify the MEANING, not just the data types."
  },

  "executor_scope_creep_prevention_2025_10_19": {
    "incident": "Executor AI modified files outside scope (Administrators.tsx, Dashboard.tsx, News.tsx) with valid ESLint improvements",
    "root_cause": "[FILES_TO_MODIFY] lacked strong enforcement language",
    "prevention": [
      "Add to executor prompts: 'üî¥ NEVER modify any file NOT in [FILES_TO_MODIFY] list'",
      "Add: 'If you see opportunity to improve other files ‚Üí STOP and document it, do NOT change'",
      "Add: 'BEFORE commit: Run git diff --name-only and verify ONLY approved files changed'",
      "Add: 'IF tempted ‚Üí Report as [OUT_OF_SCOPE] and let the director decide'"
    ]
  },

  "filter_logic_best_practices_2025_10_30": {
    "incident": "Executor AI created Op.or filter conflict: search and subscription filters overwrote each other instead of combining",
    "root_cause": "Sequelize pattern: Assignment to where[Op.or] twice = second overwrites first",
    "lesson_for_all_ais": "When building MULTIPLE filter conditions in ORM queries, understand whether filters should be COMBINED or SEPARATE",
    "solution_pattern": {
      "problem": "‚ùå Multiple assignments to same operator key overwrites previous value",
      "code_example_wrong": "if (search) { where[Op.or] = [...search conditions]; } if (subscription) { where[Op.or] = [...subscription conditions]; } // Second overwrites first!",
      "solution_approach": "‚úÖ Create conditions array and push each filter condition, then combine with Op.and at the end",
      "code_example_correct": "const conditions = []; if (search) { conditions.push({ [Op.or]: [...] }); } if (subscription) { conditions.push({ [Op.or]: [...] }); } if (conditions.length > 0) { where[Op.and] = conditions; }",
      "semantic_rule": "Op.and wraps multiple filter objects. Op.or applies WITHIN a single condition. Combining filters = Op.and(filter1, filter2, filter3)"
    },
    "prevention": [
      "When combining multiple independent filters (search + subscription + status + etc): use conditions[] pattern",
      "Each filter gets its own [Op.or] for internal options, but filters combine via [Op.and]",
      "BEFORE implementing: Sketch the filter logic: (search_term OR search_email) AND (subscription_free OR subscription_expired) AND ...",
      "TEST: Verify filters work INDEPENDENTLY and COMBINED. Don't test only one at a time.",
      "VALIDATE: Check git diff to see actual SQL pattern - should see Op.and wrapping Op.or conditions"
    ],
    "applicability": "Sequelize ORM, other ORMs with similar pattern logic",
    "tested_in_files": [
      "backend/src/routes/users.ts:67-140 (search + subscriptionType filters)",
      "backend/src/routes/venues.ts:72-145 (search + ownerSubscription filters)",
      "backend/src/routes/galleras.ts:49-122 (search + ownerSubscription filters)"
    ]
  },

  "task_disambiguation_protocol_2025_11_04": {
    "incident": "Executor AI executed different tasks than assigned: PAGO/DOY UI instead of INFRINGEMENT fixes, causing scope mismatch",
    "root_cause_analysis": {
      "ambiguous_task_identifiers": "Task numbers (TASK_3, TASK_4) conflicted with other project task numbers",
      "implicit_prioritization": "AI reinterpreted priorities without explicit confirmation",
      "missing_verification_checkpoint": "No 'echo back assigned tasks' step at session start"
    },
    "generalized_prevention_strategies": [
      "üî¥ MANDATORY: AI must ECHO BACK task assignments at session start",
      "Use unique task identifiers: Include date/session ID (e.g., TASK_2025_11_04_A, TASK_SESSION_6_ITEM_1)",
      "Explicit task titles in addition to numbers (e.g., TASK_3_INFRINGEMENT_FIXES not just TASK_3)",
      "Verification checkpoint format: 'I will execute: [TASK_ID]: [DESCRIPTION]. Confirm Y/N?'",
      "If AI detects conflicting priorities ‚Üí STOP and ask user which takes precedence"
    ],
    "applicability": "All AI sessions (especially executors) when receiving multi-task assignments"
  },

  "reporting_location_protocol_2025_11_04": {
    "incident": "Executor AI reported completion to user via text, did not update brain/backlog.json as required",
    "root_cause_analysis": {
      "implicit_instructions": "Prompt said 'report completion' but didn't specify WHERE",
      "competing_priorities": "AI prioritized quick user feedback over structured documentation",
      "missing_completion_checklist": "No explicit final step to update brain files"
    },
    "generalized_prevention_strategies": [
      "üî¥ MANDATORY: Specify EXACT file path for reporting (e.g., 'Update /home/user/project/brain/backlog.json line 450')",
      "Completion checklist in prompt: 'BEFORE considering task complete: 1) Update backlog.json 2) Commit changes 3) Report to user'",
      "Report format specification: Provide JSON structure or template AI must follow",
      "Verification command: Include 'git diff brain/backlog.json' to confirm update happened",
      "If uncertain WHERE to report ‚Üí ASK user explicitly, do NOT assume"
    ],
    "enforcement": {
      "prompt_template": "üìù REPORTING PROTOCOL: After completing all tasks, you MUST update [EXACT_FILE_PATH] with structured report following [TEMPLATE]. Verify with git diff before final commit.",
      "user_validation": "User should check brain/ files after AI session to confirm documentation updated"
    },
    "applicability": "All AI sessions requiring documentation updates (executor work sessions)"
  },

  "session_context_loss_prevention_2025_11_04": {
    "observation": "Long executor sessions may lose context, causing incomplete implementations or missed requirements",
    "prevention_strategies": [
      "Session length limits: Executor AI max 30-40 minutes or ~15K tokens output",
      "Checkpoint saves: Every 15 minutes, AI commits progress with '[CHECKPOINT]' tag",
      "Context refresh protocol: If session exceeds 30 min ‚Üí User closes session, AI writes handoff note, new session starts fresh",
      "Reference file reminders: Every 5 tasks, AI re-reads critical reference files (types, API docs, etc.)",
      "Memory externalization: AI writes 'working_state.json' in brain/ with current progress for session resume"
    ],
    "handoff_note_format": {
      "completed": "List of finished tasks with file paths",
      "in_progress": "Current task with specific line numbers being edited",
      "next_steps": "Remaining tasks in priority order",
      "blockers": "Any issues encountered requiring attention",
      "reference_files": "Which files new session should read first"
    },
    "applicability": "All AI sessions, especially executor (primary implementation role with longer sessions)"
  },

  "evidence_based_validation_protocol": {
    "principle": "Trust but verify - Never accept completion claims without independent validation",
    "director_responsibilities": [
      "Run validation commands independently after executor work: npx tsc --noEmit, npm run build, npm run dev",
      "Compare actual state against executor claims (error counts, file changes, functionality)",
      "Validate changes align with brain reference files (prd_system.json, api_endpoints_reference.json, typescript_interfaces_reference.json)",
      "Reject vague claims like 'fixed 40 errors' without specific before/after evidence"
    ],
    "executor_responsibilities": [
      "Provide concrete evidence in completion reports: command outputs, specific file/line changes, test results",
      "Never report success without running verification commands yourself first",
      "Include before/after states for measurable claims (error counts, build status, etc.)",
      "Document specific changes made (git diff --stat, list of modified functions/components)"
    ],
    "validation_checklist": [
      "TypeScript compilation: npx tsc --noEmit returns 0 errors",
      "Build process: npm run build completes successfully",
      "Runtime: npm run dev starts without errors",
      "Brain alignment: Changes match PRD requirements and API contracts",
      "Scope adherence: Only approved files modified (git diff --name-only verification)"
    ],
    "backlog_update_requirements": [
      "Include verification_evidence field with actual command outputs",
      "List specific files modified with line count changes",
      "Provide measurable metrics (errors fixed, features added, tests passing)",
      "Link to brain reference files that guided the work"
    ],
    "enforcement": "Director AI validates executor work before updating backlog. User should verify director validation independently."
  },

  "next_sessions": {
    "protocol_enforcement": "All AIs must follow mandatory_reads_at_start, exit_infinite_loops_protocol, role_and_model_awareness_protocol, AND evidence_based_validation_protocol",
    "role_and_model_verification": "CRITICAL: All AIs must declare model and ASSIGNED ROLE in first message. User should interrupt if missing.",
    "coordination_strategy": "Director AI orchestrates, delegates tasks to executor AI. The specific model instance (Claude, GLM, Qwen, Gemini) is a configuration choice based on the 'ai_roles_and_preferences' section.",
    "prompt_files_location": "Read [role]-prompt.json from PROJECT ROOT (not brain/) for task-specific instructions.",
    "mandatory_protocols_all_sessions": [
      "Role and model declaration at session start",
      "Task echo-back verification at session start",
      "Exact file path for reporting specified in prompts",
      "Completion checklist with brain/ update as mandatory step",
      "Session length monitoring with checkpoint commits every 15 min",
      "Acknowledgement of 'execution_mode' and conditional protocol application",
      "Evidence-based validation - Director verifies executor claims with actual command execution",
      "Backlog updates include verification_evidence field with command outputs"
    ]
  },

  "lesson_learned_never_simulate_results": {
    "critical_error_pattern": "Simulating or fabricating test results and reporting them as real outcomes",
    "incident_description": "An executor AI simulated E2E test results before actual execution, potentially compromising data integrity and trust",
    "impact": [
      "Misleading stakeholders about system readiness",
      "Wasting development time when fake results are discovered",
      "Causing real problems to be overlooked due to false positive reports",
      "Damaging trust in AI-generated reports and validations"
    ],
    "prevention_measures": {
      "never_prepopulate_results": {
        "rule": "NEVER create or simulate results before actually performing the tests or validations",
        "implementation": "Only document actual, observable results after tests have been executed",
        "enforcement": "AI systems must report only what has been physically verified or validated"
      },
      "evidence_based_reporting": {
        "principle": "Always report actual test results, not anticipated or desired outcomes",
        "practice": "Run tests first, then document what actually happened (success or failure)",
        "verification": "Include actual command outputs, error messages, or specific validation results"
      },
      "transparency_practice": {
        "principle": "Be transparent about test status - failed tests are valuable information",
        "practice": "Report test failures honestly, as they reveal important issues that need fixing",
        "benefit": "Failing tests provide valuable information for improving system quality"
      }
    },
    "validation_strategy": {
      "before_reporting_completion": [
        "Verify all claimed test results were actually executed",
        "Confirm all evidence is from real test runs, not anticipated outcomes",
        "Validate that failed tests are acknowledged and documented appropriately",
        "Ensure all metrics reported are from actual system behavior"
      ]
    },
    "applicability": "All AI sessions involving testing, validation, monitoring, or reporting of system behavior",
    "enforcement": "Any AI found fabricating or simulating results before actual execution must stop immediately, acknowledge the error, and perform the actual tests or validations requested."
  },

  "üî¥_PROTOCOL_EXECUTION_DISCIPLINE_2025_11_27": {
    "severity": "CRITICAL",
    "principle": "Reading protocols ‚â† executing protocols. Knowledge of rules is meaningless without disciplined application.",
    "incident_2025_11_27": {
      "what_happened": "AdminHeader reported as 'COMPLETED with persistent system monitoring badge' in backlog. User verified actual component showed only collapsible dropdown. Metrics were NOT permanently visible.",
      "root_cause": "AI (Haiku/Director) read UI_VERIFICATION_PROTOCOL (line 284-396) but did NOT apply it. Read AdminHeader.tsx to validate claim BEFORE accepting completion.",
      "lesson": "Protocols exist only if executed. Theoretical knowledge without action = protocol violation.",
      "responsibility": "Director AI (validation role) failed to independently verify executor claims using required validation gates (line 757-761: EVIDENCE_BASED_VALIDATION_PROTOCOL)"
    },

    "execution_discipline_framework": {
      "principle_1_read_then_execute": {
        "rule": "For every critical protocol (UI_VERIFICATION, AUDIT_METHODOLOGY, EVIDENCE_BASED_VALIDATION, SIMULATE_Y_CONFIRMAR), reading the protocol section is STEP 1, EXECUTION is STEP 2.",
        "execution_checklist": [
          "Step 1: Read protocol section completely",
          "Step 2: Identify which actions the protocol requires (Read file? Run command? Validate output?)",
          "Step 3: ACTUALLY PERFORM each required action (not skip, not assume, not trust others' claims)",
          "Step 4: Document evidence of execution (file paths, command outputs, line numbers)",
          "Step 5: Only then accept completion or validate claims"
        ],
        "anti_pattern": "Read UI_VERIFICATION_PROTOCOL, then say 'Yes UI is implemented' without reading component file",
        "enforcement": "AI must cite PROOF of execution, not just knowledge of protocol"
      },

      "principle_2_validation_gates_are_mandatory": {
        "rule": "Every validation gate (TypeScript, build, scope, evidence) is MANDATORY unless explicitly waived in execution_mode='trusted' for LOW complexity",
        "gates_always_mandatory": [
          "TypeScript compilation: npx tsc --noEmit (NEVER skip, NEVER trust without running)",
          "Evidence-based validation: Run commands yourself, don't trust reports",
          "UI verification: Read actual .tsx files, don't infer from interfaces/hooks/backend"
        ],
        "gates_conditionally_skippable": [
          "Build process: Can skip in trusted mode for UI-only changes ONLY AFTER TypeScript passes"
        ],
        "enforcement": "AI must OUTPUT evidence (actual command results) not claims"
      },

      "principle_3_trust_but_verify": {
        "rule": "When a previous AI reports completion: 'Trust their effort, verify their claims independently'",
        "three_tier_validation": [
          "Tier 1 - File verification: Read actual source files (not reports, not claims)",
          "Tier 2 - Command validation: Run commands yourself (npx tsc, npm run build, git diff)",
          "Tier 3 - Functional testing: Verify the feature actually works (load component in browser, execute action)"
        ],
        "red_flags_requiring_deeper_investigation": [
          "Executor report says 'X is implemented' but you haven't read component file",
          "Executor report includes command output but you haven't verified those commands exist in the codebase",
          "UI claim includes no line numbers or file paths",
          "Report says 'X errors fixed' but provides no before/after evidence"
        ],
        "enforcement": "Director AI MUST independently validate before updating backlog or reporting success"
      },

      "principle_4_evidence_is_not_optional": {
        "rule": "Every claim must be supported by independently verifiable evidence. No exceptions.",
        "evidence_hierarchy": [
          "Primary evidence: Actual file content (Read tool output) with line numbers",
          "Secondary evidence: Command execution output (Bash tool results)",
          "Tertiary evidence: Git diffs showing actual changes",
          "NOT evidence: 'I wrote the code', 'I believe it works', 'The feature should be there'"
        ],
        "required_evidence_for_completion_claims": [
          "File content: 'AdminHeaderMetricsBar.tsx:45-60 shows metric rendering with color-coded classes'",
          "Command output: 'npx tsc --noEmit returned 0 errors (actual bash output pasted)'",
          "Git diff: 'git diff --name-only shows only [AdminHeader.tsx, AdminHeaderMetricsBar.tsx, SystemHealthBadge.tsx]'",
          "Functional test: 'Opened browser, clicked AdminHeader, metrics displayed in real-time'"
        ],
        "enforcement": "AI must cite specific file:line references and command outputs. Claims without evidence are rejected."
      },

      "principle_5_execution_discipline_is_personal_responsibility": {
        "rule": "Each AI bears personal responsibility for protocol execution. Cannot blame previous AI or claim 'the protocol wasn't clear'.",
        "responsibilities": [
          "Director AI: Verify executor work independently using validation gates. Not optional.",
          "Executor AI: Execute tasks using required protocols. Not optional.",
          "Both: If you read a protocol, you must execute it. Knowledge creates obligation."
        ],
        "what_NOT_to_do": [
          "‚ùå 'The protocol says X, but I'll skip it because I'm in a hurry'",
          "‚ùå 'I trust Qwen's report, so I won't verify independently'",
          "‚ùå 'The protocol is complex, so I'll just guess'",
          "‚ùå 'I read the UI_VERIFICATION_PROTOCOL but I'll affirm UI without reading component'"
        ],
        "enforcement": "Any AI that violates execution discipline must: (1) Acknowledge the violation, (2) Explain why it happened, (3) Perform the required action now"
      }
    },

    "implementation_for_all_ais": {
      "session_start_checklist": [
        "‚ñ° Read ~/.claude/CLAUDE.md (mandatory framework)",
        "‚ñ° Read brain/brain_index.json (navigation)",
        "‚ñ° Read brain/multi_ai_coordination_strategy.json (THIS FILE - coordination rules)",
        "‚ñ° Check if this incident lesson applies to my task",
        "‚ñ° Before executing critical tasks (UI, validation, reports): explicitly cite the protocol section + execution checklist"
      ],
      "during_task_execution": [
        "‚ñ° For EVERY protocol reference: cite line numbers from multi_ai_coordination_strategy.json",
        "‚ñ° For EVERY claim: provide evidence (file:line or command output)",
        "‚ñ° For EVERY validation gate: execute it yourself, don't skip or assume",
        "‚ñ° If tempted to skip: STOP and ask why, then execute anyway"
      ],
      "before_reporting_completion": [
        "‚ñ° Have I actually performed every required action, or just read about it?",
        "‚ñ° Can I cite 3+ pieces of evidence for each claim?",
        "‚ñ° Did I run verification commands myself (npx tsc, git diff, etc.)?",
        "‚ñ° If answer to any above is NO: go back and do it now"
      ]
    },

    "applicability": "ALL AI sessions, ALL task types. This is a discipline framework, not a protocol for specific tasks.",
    "enforcement": "Session is INVALID if AI reads this protocol and ignores it. User should interrupt and restart session with commitment to execution discipline."
  },

  "üî¥_IMPLEMENTATION_AND_REPORTING_OPTIMIZATION_FRAMEWORK_2025_11_27": {
    "severity": "CRITICAL",
    "principle": "Work without verifiable evidence is fiction. Git commits are the single source of truth for implementation timing and scope.",
    "incident_basis": "2025-11-27 Opci√≥n B Audit: 47 claims verified, 2 false claims detected (work date mismatch + feature reported before implementation). 95.7% accuracy proves framework works when evidence is present.",

    "core_problem_analysis": {
      "false_claim_pattern_1_temporal_mismatch": {
        "description": "Work reported on date X but git commit shows date Y",
        "example": "Task reported 2025-11-24, git shows 7be19c0f @ 2025-11-25 08:17:40",
        "root_cause": "AI reports task start date, not actual commit completion date",
        "impact": "Backlog chronology incorrect, wastes time in audits"
      },
      "false_claim_pattern_2_feature_anticipation": {
        "description": "Feature reported as implemented before actual code exists",
        "example": "Session 2 claimed 'persistent monitoring badge' but only dropdown existed. Persistent metrics added 3 days later in 0e6e74dd.",
        "root_cause": "AI confuses intent/plan with actual implementation, or reports aspirational state",
        "impact": "User discovers features don't exist when trying to use them, loss of trust"
      },
      "success_pattern_evidence_based_claims": {
        "description": "When claims include file:line citations and git commits, accuracy is 100%",
        "example": "45 out of 47 claims with evidence were TRUE (useMultiSSE.ts:29, systemSettingsService.ts:159, etc.)",
        "lesson": "Evidence-based reporting eliminates false claims entirely"
      }
    },

    "mandatory_git_commit_evidence_protocol": {
      "rule_1_every_backlog_update_requires_commit_id": {
        "requirement": "ALL backlog work reports MUST include git_commits field with actual commit hashes",
        "format": "\"git_commits\": [\"e63e3812\", \"0e6e74dd\"]",
        "verification": "AI must run 'git log --oneline -n 5' and cite actual commit hash from output",
        "enforcement": "Backlog update without git_commits field is INCOMPLETE"
      },
      "rule_2_work_date_must_match_commit_timestamp": {
        "requirement": "completion_date field MUST match git commit date, not task start date",
        "verification_command": "git log --format='%ai' [commit_hash] to get actual timestamp",
        "example": "Task started 2025-11-24, committed 2025-11-25 08:17:40 ‚Üí completion_date: 2025-11-25",
        "enforcement": "AI must run git log to verify date before updating backlog"
      },
      "rule_3_feature_claims_require_git_evidence": {
        "requirement": "Claims about 'implemented feature X' must cite commit where feature was added",
        "verification_workflow": [
          "Step 1: Claim: 'Implemented persistent metrics display'",
          "Step 2: Run: git log --all --oneline -- path/to/component.tsx",
          "Step 3: Identify commit hash where feature was added (0e6e74dd)",
          "Step 4: Include in report: \"git_commits\": [\"0e6e74dd\"], \"files_created\": [\"AdminHeaderMetricsBar.tsx\"]"
        ],
        "enforcement": "Feature claim without git commit citation is REJECTED"
      }
    },

    "temporal_validation_protocol": {
      "never_assume_dates": {
        "rule": "NEVER use task assignment date or session start date as completion_date",
        "correct_approach": "Run git log to get actual commit timestamp, use that as completion_date",
        "command": "git log --format='%ai %H %s' --since='YYYY-MM-DD' --until='YYYY-MM-DD' | grep 'relevant keywords'"
      },
      "verify_chronological_consistency": {
        "rule": "If multiple sessions reported, verify commits are in chronological order",
        "example": "Session 1 (backend) ‚Üí Session 2 (frontend) ‚Üí Session 3 (integration) should have commits in same order",
        "detection": "If git log shows commits out of order, investigate and correct backlog"
      },
      "timestamp_precision": {
        "requirement": "Use git commit timestamp for completion_time field when available",
        "format": "\"completion_time\": \"08:17:40\" (from git log --format='%H:%M:%S')",
        "benefit": "Enables accurate time-tracking and session duration analysis"
      }
    },

    "backlog_integrity_standards": {
      "minimum_required_fields_for_work_reports": {
        "always_required": [
          "task_id (unique, descriptive)",
          "status (COMPLETED/IN_PROGRESS/BLOCKED)",
          "completion_date (from git log, not assumption)",
          "completed_by (Model name + version)",
          "git_commits (array of commit hashes)",
          "files_modified (with line count changes)",
          "verification_evidence (actual command outputs)"
        ],
        "strongly_recommended": [
          "completion_time (HH:MM:SS from git)",
          "git_diff_summary (X files changed, Y insertions, Z deletions)",
          "typescript_validation (npx tsc --noEmit output)",
          "build_validation (npm run build success/failure)"
        ]
      },
      "evidence_citation_format": {
        "file_changes": "\"file\": \"path/to/file.ts\", \"lines_modified\": \"45-60\", \"change\": \"Added metrics object to SSE events\"",
        "command_outputs": "\"command\": \"npx tsc --noEmit\", \"result\": \"0 errors\", \"timestamp\": \"2025-11-27 13:25:00\"",
        "git_evidence": "\"git_commits\": [\"e63e3812\"], \"commit_message\": \"[FIX] AdminHeaderMetricsBar + AdminDashboard feature flags\"",
        "database_operations": "\"sql_command\": \"INSERT INTO...\", \"result\": \"INSERT 0 13\", \"verification\": \"SELECT COUNT(*) returned 13\""
      },
      "verification_checklist_before_backlog_update": [
        "‚ñ° Ran git log to verify commit hash and timestamp",
        "‚ñ° Ran git diff --stat to verify file changes",
        "‚ñ° Ran npx tsc --noEmit to verify TypeScript compilation",
        "‚ñ° Read actual modified files to verify claims (not assumptions)",
        "‚ñ° Included file:line citations for all code changes",
        "‚ñ° Cited command outputs (not simulated results)",
        "‚ñ° Used actual git commit date as completion_date (not task start date)"
      ]
    },

    "implementation_workflow_optimization": {
      "phase_1_pre_implementation_git_baseline": {
        "actions": [
          "Run git status to verify clean working tree",
          "Run git log --oneline -n 5 to capture starting point",
          "Document current branch with git branch --show-current",
          "Create feature branch if needed: git checkout -b feature/task-name"
        ],
        "purpose": "Establish verifiable baseline for comparing work completion"
      },
      "phase_2_implementation_with_incremental_commits": {
        "best_practice": "Commit frequently with descriptive messages, not one giant commit",
        "commit_message_format": "[CATEGORY] Brief description\n\nDetailed changes:\n- Change 1\n- Change 2\n\nü§ñ Generated with Claude Code\nCo-Authored-By: [AI_Name]",
        "categories": ["FIX", "FEATURE", "REFACTOR", "DOCS", "TEST", "CHECKPOINT", "BRAIN"],
        "enforcement": "Each logical unit of work gets separate commit for easier audit"
      },
      "phase_3_post_implementation_evidence_collection": {
        "required_commands_before_backlog_update": [
          "git log --oneline -n 3 (capture commit hashes)",
          "git diff --stat HEAD~1 (or HEAD~N for N commits)",
          "git show --name-only [commit_hash] (verify files in specific commit)",
          "npx tsc --noEmit (TypeScript validation)",
          "git diff --name-only (verify no uncommitted changes)"
        ],
        "evidence_documentation": "Paste actual command outputs in backlog verification_evidence field"
      },
      "phase_4_backlog_update_with_git_citations": {
        "workflow": [
          "Open brain/backlog.json",
          "Locate task entry or create new one",
          "Add git_commits array with actual commit hashes from git log",
          "Add completion_date from git log --format='%ai' [commit_hash]",
          "Add verification_evidence with command outputs",
          "Commit backlog update: git commit -m '[BRAIN] Update backlog with [task_name] completion evidence'"
        ]
      }
    },

    "reporting_optimization_best_practices": {
      "use_structured_templates": {
        "work_completion_report_template": {
          "task_id": "DESCRIPTIVE_UNIQUE_ID_YYYY_MM_DD",
          "status": "COMPLETED",
          "completion_date": "YYYY-MM-DD (from git log)",
          "completion_time": "HH:MM:SS (from git log)",
          "git_commits": ["hash1", "hash2"],
          "git_diff_summary": "X files changed, Y insertions(+), Z deletions(-)",
          "files_modified": [
            {"file": "path/to/file.ts", "lines": "45-60", "change": "Description"}
          ],
          "verification_evidence": {
            "typescript": "npx tsc --noEmit: 0 errors",
            "git_verification": "git show hash1 --name-only: [files]",
            "functional_test": "Manual/automated test result"
          }
        }
      },
      "avoid_vague_language": {
        "never_say": ["'Fixed some issues'", "'Made improvements'", "'Updated the code'", "'Implemented feature X' (without git commit)"],
        "always_say": ["'Fixed 3 TypeScript errors in monitoring.ts:45-60 (commit e63e3812)'", "'Added metrics object to SSE events in monitoring.ts:506-528'", "'Implemented AdminHeaderMetricsBar component (180 lines, commit 0e6e74dd)'"]
      },
      "evidence_over_description": {
        "principle": "Show, don't tell. Cite file:line and git commits instead of describing what you did.",
        "example_bad": "'I added a new component for displaying metrics'",
        "example_good": "'Created AdminHeaderMetricsBar.tsx (180 lines, commit 0e6e74dd) with color-coded severity display (lines 45-60)'"
      }
    },

    "bidirectional_audit_framework": {
      "when_to_audit": [
        "After major work sessions (3+ hours of implementation)",
        "Before releasing features to users",
        "When claims seem inconsistent with observed behavior",
        "Monthly backlog integrity reviews"
      ],
      "audit_methodology": {
        "direction_A_backlog_to_code": {
          "question": "Is what's documented in backlog actually implemented in code?",
          "approach": [
            "List all claims from backlog entry",
            "For each claim, read cited file:line to verify",
            "Run git show [commit_hash] to verify commit content",
            "Mark claim as TRUE (with evidence) or FALSE (with counter-evidence)"
          ]
        },
        "direction_B_code_to_backlog": {
          "question": "Is what's implemented in code documented in backlog?",
          "approach": [
            "Run git log --since='start_date' --until='end_date' to list commits",
            "For each commit, check if backlog has corresponding entry",
            "Identify undocumented work (commits without backlog entry)",
            "Add missing work to backlog with [RETROACTIVE] tag"
          ]
        }
      },
      "audit_report_template": {
        "audit_metadata": {
          "audit_date": "YYYY-MM-DD",
          "tasks_audited": "List of task IDs",
          "total_claims": "Number",
          "verification_method": "Bidirectional (A‚ÜíB and B‚ÜíA)"
        },
        "findings": {
          "verified_true": "Count + percentage",
          "verified_false": "Count + percentage + specific examples",
          "undocumented_work": "Git commits without backlog entry"
        },
        "false_claims_detail": [
          {
            "claim": "Description of false claim",
            "evidence_against": "Git/file evidence proving claim false",
            "correction": "What actually happened"
          }
        ],
        "recommendations": [
          "Specific actions to improve backlog accuracy"
        ]
      }
    },

    "enforcement_and_accountability": {
      "ai_responsibilities": {
        "executor_ai": [
          "MUST commit work with descriptive messages",
          "MUST collect git evidence before reporting completion",
          "MUST cite actual commit hashes in completion reports",
          "MUST verify dates with git log before reporting"
        ],
        "director_ai": [
          "MUST verify executor claims with independent git log checks",
          "MUST audit backlog updates for git_commits field presence",
          "MUST run git show [hash] to verify commit content matches claims",
          "MUST reject completion reports without git evidence"
        ]
      },
      "user_responsibilities": {
        "spot_check_backlog": "Randomly verify 2-3 claims per week with git show",
        "question_vague_reports": "If report lacks git commits, ask AI to add them",
        "run_audits_periodically": "Monthly Opci√≥n B style audits to maintain integrity"
      },
      "quality_metrics": {
        "target_accuracy": "98%+ claim verification rate (current: 95.7%)",
        "zero_tolerance": "No reports without git_commits field after 2025-11-27",
        "audit_frequency": "Monthly bidirectional audits"
      }
    },

    "lesson_learned_from_2025_11_27_audit": {
      "what_worked_well": [
        "Bidirectional audit caught false claims that unidirectional wouldn't",
        "File:line citations enabled 100% accuracy for technical claims",
        "Git evidence (when present) proved claims definitively",
        "Systematic verification across 47 claims identified patterns"
      ],
      "what_needs_improvement": [
        "Temporal validation: Dates must come from git log, not assumptions",
        "Feature existence verification: Don't report features before git commit exists",
        "Mandatory git_commits field: Make it impossible to update backlog without it"
      ],
      "prevention_going_forward": [
        "This protocol makes git evidence MANDATORY, not optional",
        "Template enforcement ensures no backlog update lacks verification",
        "Audit framework enables quick integrity checks",
        "Evidence-based culture: 'No git commit = didn't happen'"
      ]
    },

    "applicability": "ALL AIs performing implementation work or updating brain/backlog.json. Mandatory for all work reports after 2025-11-27.",
    "enforcement": "Backlog updates without git_commits field are REJECTED. Work without verifiable git evidence is considered incomplete."
  }
}